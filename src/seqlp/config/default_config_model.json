{
    "num_hidden_layers": 12,
    "num_attention_heads": 8,
    "hidden_size": 768,
    "d_ff": 3072,
    "vocab_size": 33,
    "max_len": 150,
    "max_position_embeddings": 152,
    "batch_size": 96,
    "max_steps": 225000,
    "weight_decay": 0.01,
    "peak_learning_rate": 0.0001
    }